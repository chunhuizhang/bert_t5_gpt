{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f94bf3-26da-4976-85bf-a6258487c2bb",
   "metadata": {},
   "source": [
    "```\n",
    "ImportError: PyTorch SDPA requirements in Transformers are not met. Please install torch>=2.1.1.\n",
    "```\n",
    "\n",
    "- https://pytorch.org/tutorials/intermediate/scaled_dot_product_attention_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59c5a0c-1a27-4ef7-9c88-e6272dbc7074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:12:46.998762Z",
     "iopub.status.busy": "2024-07-02T15:12:46.998452Z",
     "iopub.status.idle": "2024-07-02T15:12:48.284108Z",
     "shell.execute_reply": "2024-07-02T15:12:48.283126Z",
     "shell.execute_reply.started": "2024-07-02T15:12:46.998741Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ac02c7-8351-4fcd-865e-4bba2ba9dec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:48.763026Z",
     "iopub.status.busy": "2024-07-02T15:05:48.762834Z",
     "iopub.status.idle": "2024-07-02T15:05:48.769584Z",
     "shell.execute_reply": "2024-07-02T15:05:48.768865Z",
     "shell.execute_reply.started": "2024-07-02T15:05:48.763013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6db2751f-19a6-4448-be0c-7d1f879eb691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:48.772098Z",
     "iopub.status.busy": "2024-07-02T15:05:48.771972Z",
     "iopub.status.idle": "2024-07-02T15:05:48.976738Z",
     "shell.execute_reply": "2024-07-02T15:05:48.975924Z",
     "shell.execute_reply.started": "2024-07-02T15:05:48.772088Z"
    }
   },
   "outputs": [],
   "source": [
    "Q, K, V = torch.randn(2, 3, 8, device=device), torch.randn(2, 3, 8, device=device), torch.randn(2, 3, 8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2abcd4-739b-4f09-b865-eb70a00f5bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:48.977481Z",
     "iopub.status.busy": "2024-07-02T15:05:48.977339Z",
     "iopub.status.idle": "2024-07-02T15:05:49.101062Z",
     "shell.execute_reply": "2024-07-02T15:05:49.100255Z",
     "shell.execute_reply.started": "2024-07-02T15:05:48.977470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3321, -0.3489,  0.3015, -0.3912,  0.9867,  0.3137, -0.0691,\n",
       "          -1.2593],\n",
       "         [-1.0882,  0.2506,  0.6491,  0.1360,  0.5238, -0.2448, -0.0820,\n",
       "          -0.6171],\n",
       "         [-1.0012,  0.3990,  0.6441, -0.0277,  0.5325, -0.2564, -0.0607,\n",
       "          -0.6404]],\n",
       "\n",
       "        [[ 0.6091,  0.0708,  0.6188,  0.3252, -0.1598,  0.4197, -0.2335,\n",
       "           0.0630],\n",
       "         [ 0.5285,  0.3890, -0.2649,  0.3706, -0.3839,  0.1963, -0.6242,\n",
       "           0.2312],\n",
       "         [ 0.4048,  0.0762,  0.3777,  0.4689, -0.2978,  0.2754, -0.6429,\n",
       "           0.1037]]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = F.scaled_dot_product_attention(Q, K, V)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd841a4-31fb-48ef-afec-688885ca3530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:49.101951Z",
     "iopub.status.busy": "2024-07-02T15:05:49.101810Z",
     "iopub.status.idle": "2024-07-02T15:05:49.106562Z",
     "shell.execute_reply": "2024-07-02T15:05:49.105870Z",
     "shell.execute_reply.started": "2024-07-02T15:05:49.101940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe003f93-842c-4543-937b-10ea43bef115",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aef6873-4e1f-4ebc-a4cf-38fb0ce8c97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:49.107070Z",
     "iopub.status.busy": "2024-07-02T15:05:49.106948Z",
     "iopub.status.idle": "2024-07-02T15:05:49.117089Z",
     "shell.execute_reply": "2024-07-02T15:05:49.116379Z",
     "shell.execute_reply.started": "2024-07-02T15:05:49.107061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.bmm(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(8)), dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379a7c31-3351-4c43-a8d1-15c43543099e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:49.117574Z",
     "iopub.status.busy": "2024-07-02T15:05:49.117453Z",
     "iopub.status.idle": "2024-07-02T15:05:49.125447Z",
     "shell.execute_reply": "2024-07-02T15:05:49.124733Z",
     "shell.execute_reply.started": "2024-07-02T15:05:49.117565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3321, -0.3489,  0.3015, -0.3912,  0.9867,  0.3137, -0.0691,\n",
       "          -1.2593],\n",
       "         [-1.0882,  0.2506,  0.6491,  0.1360,  0.5238, -0.2448, -0.0820,\n",
       "          -0.6171],\n",
       "         [-1.0012,  0.3990,  0.6441, -0.0277,  0.5325, -0.2564, -0.0607,\n",
       "          -0.6404]],\n",
       "\n",
       "        [[ 0.6091,  0.0708,  0.6188,  0.3252, -0.1598,  0.4197, -0.2335,\n",
       "           0.0630],\n",
       "         [ 0.5285,  0.3890, -0.2649,  0.3706, -0.3839,  0.1963, -0.6242,\n",
       "           0.2312],\n",
       "         [ 0.4048,  0.0762,  0.3777,  0.4689, -0.2978,  0.2754, -0.6429,\n",
       "           0.1037]]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(F.softmax(torch.bmm(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(8)), dim=-1), V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb1ef1-27ac-4999-a823-898fa6710f9e",
   "metadata": {},
   "source": [
    "## SDPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269f52b-c544-4667-b37e-09d691cb4b23",
   "metadata": {},
   "source": [
    "- The default implementation runs in 26186.948 microseconds\n",
    "- The math implementation runs in 50155.869 microseconds\n",
    "- The flash attention implementation runs in 26189.985 microseconds\n",
    "- The memory efficient implementation runs in 48395.111 microseconds\n",
    "- PyTorchâ€™s `torch.nn.functional.scaled_dot_product_attention` (SDPA) can also call `FlashAttention` and `memory-efficient attention kernels` under the hood. SDPA support is currently being added natively in Transformers and is used by default for torch>=2.1.1 when an implementation is available. You may also set attn_implementation=\"sdpa\" in from_pretrained() to explicitly request SDPA to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfeb170-a94d-4b44-b677-50661f84997e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:49.125932Z",
     "iopub.status.busy": "2024-07-02T15:05:49.125814Z",
     "iopub.status.idle": "2024-07-02T15:05:49.570913Z",
     "shell.execute_reply": "2024-07-02T15:05:49.570110Z",
     "shell.execute_reply.started": "2024-07-02T15:05:49.125923Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "def benchmark_sdpa(f, *args, **kwargs):\n",
    "    t0 = benchmark.Timer(\n",
    "        stmt=\"f(*args, **kwargs)\", globals={\"args\": args, \"kwargs\": kwargs, \"f\": f}\n",
    "    )\n",
    "    return t0.blocked_autorange().mean * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9193fa4d-c7ea-4c68-9e0b-2cfbd50b74fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:12:55.295467Z",
     "iopub.status.busy": "2024-07-02T15:12:55.294255Z",
     "iopub.status.idle": "2024-07-02T15:12:55.301016Z",
     "shell.execute_reply": "2024-07-02T15:12:55.299617Z",
     "shell.execute_reply.started": "2024-07-02T15:12:55.295438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lets define the hyper-parameters of our input\n",
    "bs = 32\n",
    "seq_len = 2*1024\n",
    "n_heads = 32\n",
    "embed_dimen = 224\n",
    "\n",
    "dtype = torch.float16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c68446-cf47-4d68-91c1-5dec446f0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.rand(bs, n_heads, seq_len, embed_dimen, device=device, dtype=dtype)\n",
    "K = torch.rand(bs, n_heads, seq_len, embed_dimen, device=device, dtype=dtype)\n",
    "V = torch.rand(bs, n_heads, seq_len, embed_dimen, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec84edf-b722-4814-919e-6f6d09b57dd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:49.578084Z",
     "iopub.status.busy": "2024-07-02T15:05:49.577955Z",
     "iopub.status.idle": "2024-07-02T15:05:50.162879Z",
     "shell.execute_reply": "2024-07-02T15:05:50.162281Z",
     "shell.execute_reply.started": "2024-07-02T15:05:49.578074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The default implementation runs in 26186.948 microseconds'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The default implementation runs in {benchmark_sdpa(F.scaled_dot_product_attention, Q, K, V):.3f} microseconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f001cf-ba79-4140-8c9b-cfc2f39bf0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:50.164028Z",
     "iopub.status.busy": "2024-07-02T15:05:50.163666Z",
     "iopub.status.idle": "2024-07-02T15:05:50.481653Z",
     "shell.execute_reply": "2024-07-02T15:05:50.480844Z",
     "shell.execute_reply.started": "2024-07-02T15:05:50.164009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The math implementation runs in 50155.869 microseconds\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.attention import SDPBackend, sdpa_kernel\n",
    "\n",
    "with sdpa_kernel(SDPBackend.MATH):\n",
    "    math_time=benchmark_sdpa(F.scaled_dot_product_attention, Q, K, V)\n",
    "    print(f\"The math implementation runs in {math_time:.3f} microseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87f6899-c162-428f-8b7f-b18baeacecad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:05:58.633412Z",
     "iopub.status.busy": "2024-07-02T15:05:58.633077Z",
     "iopub.status.idle": "2024-07-02T15:05:59.205359Z",
     "shell.execute_reply": "2024-07-02T15:05:59.204730Z",
     "shell.execute_reply.started": "2024-07-02T15:05:58.633389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flash attention implementation runs in 26189.985 microseconds\n"
     ]
    }
   ],
   "source": [
    "with sdpa_kernel(SDPBackend.FLASH_ATTENTION):\n",
    "    try:\n",
    "        flash_time=benchmark_sdpa(F.scaled_dot_product_attention, Q, K, V)\n",
    "        print(f\"The flash attention implementation runs in {flash_time:.3f} microseconds\")\n",
    "    except RuntimeError:\n",
    "        print(\"FlashAttention is not supported. See warnings for reasons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb0f6e8-9278-486e-b555-edc146bd456e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:06:53.362860Z",
     "iopub.status.busy": "2024-07-02T15:06:53.362229Z",
     "iopub.status.idle": "2024-07-02T15:06:53.650760Z",
     "shell.execute_reply": "2024-07-02T15:06:53.648993Z",
     "shell.execute_reply.started": "2024-07-02T15:06:53.362812Z"
    }
   },
   "outputs": [],
   "source": [
    "Q = torch.rand(bs, n_heads, seq_len, embed_dimen, device='cuda:1', dtype=dtype)\n",
    "K = torch.rand(bs, n_heads, seq_len, embed_dimen, device='cuda:1', dtype=dtype)\n",
    "V = torch.rand(bs, n_heads, seq_len, embed_dimen, device='cuda:1', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7880a7-e404-42f5-8dbd-0fe6b8e197b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:06:54.949383Z",
     "iopub.status.busy": "2024-07-02T15:06:54.949085Z",
     "iopub.status.idle": "2024-07-02T15:07:47.613700Z",
     "shell.execute_reply": "2024-07-02T15:07:47.613137Z",
     "shell.execute_reply.started": "2024-07-02T15:06:54.949363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory efficient implementation runs in 48395.111 microseconds\n"
     ]
    }
   ],
   "source": [
    "with sdpa_kernel(SDPBackend.EFFICIENT_ATTENTION):\n",
    "    try:\n",
    "        efficient_time=benchmark_sdpa(F.scaled_dot_product_attention, Q, K, V)\n",
    "        print(f\"The memory efficient implementation runs in {efficient_time:.3f} microseconds\")\n",
    "    except RuntimeError:\n",
    "        print(\"EfficientAttention is not supported. See warnings for reasons.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ddbdf-b0f2-496a-8b12-3c58ca1b706f",
   "metadata": {},
   "source": [
    "## Causal Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fcecc-d9c7-4247-abd4-bb242e916db6",
   "metadata": {},
   "source": [
    "- https://github.com/karpathy/nanoGPT/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd3030e9-43c0-4bac-b61d-e96061f7a765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:22:17.066261Z",
     "iopub.status.busy": "2024-07-02T15:22:17.065614Z",
     "iopub.status.idle": "2024-07-02T15:22:17.075431Z",
     "shell.execute_reply": "2024-07-02T15:22:17.073311Z",
     "shell.execute_reply.started": "2024-07-02T15:22:17.066214Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_dim = 12\n",
    "n_heads = 2\n",
    "assert embed_dim % n_heads == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e5240a0-29bf-4cb1-9f2f-3946f56dcdcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:22:18.856356Z",
     "iopub.status.busy": "2024-07-02T15:22:18.855662Z",
     "iopub.status.idle": "2024-07-02T15:22:18.868368Z",
     "shell.execute_reply": "2024-07-02T15:22:18.866268Z",
     "shell.execute_reply.started": "2024-07-02T15:22:18.856306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_dim = embed_dim // (n_heads * 3)\n",
    "head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58d5121e-6686-4746-8f18-ddbdea779e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:19:31.167315Z",
     "iopub.status.busy": "2024-07-02T15:19:31.166646Z",
     "iopub.status.idle": "2024-07-02T15:19:31.176478Z",
     "shell.execute_reply": "2024-07-02T15:19:31.174473Z",
     "shell.execute_reply.started": "2024-07-02T15:19:31.167266Z"
    }
   },
   "outputs": [],
   "source": [
    "# W_q, W_k, W_v\n",
    "c_attn = nn.Linear(embed_dim, 3 * embed_dim, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76bf52a5-2a82-4527-bd91-932dfd35a595",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:20:31.611245Z",
     "iopub.status.busy": "2024-07-02T15:20:31.610596Z",
     "iopub.status.idle": "2024-07-02T15:20:31.619783Z",
     "shell.execute_reply": "2024-07-02T15:20:31.617774Z",
     "shell.execute_reply.started": "2024-07-02T15:20:31.611199Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.randn(2, 5, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da2bea94-846c-4957-acbb-82279104f529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:20:33.388661Z",
     "iopub.status.busy": "2024-07-02T15:20:33.388036Z",
     "iopub.status.idle": "2024-07-02T15:20:33.401354Z",
     "shell.execute_reply": "2024-07-02T15:20:33.399098Z",
     "shell.execute_reply.started": "2024-07-02T15:20:33.388615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 36])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QKV = c_attn(X)\n",
    "QKV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c043d777-c0de-4368-9a25-ea37ead32aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:20:34.961676Z",
     "iopub.status.busy": "2024-07-02T15:20:34.960961Z",
     "iopub.status.idle": "2024-07-02T15:20:34.971316Z",
     "shell.execute_reply": "2024-07-02T15:20:34.969451Z",
     "shell.execute_reply.started": "2024-07-02T15:20:34.961625Z"
    }
   },
   "outputs": [],
   "source": [
    "Q, K, V = QKV.chunk(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c7bfe56-f745-4d6b-96f9-331695c484b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:20:36.556381Z",
     "iopub.status.busy": "2024-07-02T15:20:36.555665Z",
     "iopub.status.idle": "2024-07-02T15:20:36.568763Z",
     "shell.execute_reply": "2024-07-02T15:20:36.566495Z",
     "shell.execute_reply.started": "2024-07-02T15:20:36.556333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(QKV[:, :, :12], Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08163375-f669-4822-857a-5ac853a49b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:20:38.004913Z",
     "iopub.status.busy": "2024-07-02T15:20:38.004275Z",
     "iopub.status.idle": "2024-07-02T15:20:38.016953Z",
     "shell.execute_reply": "2024-07-02T15:20:38.014655Z",
     "shell.execute_reply.started": "2024-07-02T15:20:38.004867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 12])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dff3f92f-2959-4df5-b458-f9c4b576ce7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-02T15:23:07.819346Z",
     "iopub.status.busy": "2024-07-02T15:23:07.818703Z",
     "iopub.status.idle": "2024-07-02T15:23:07.830667Z",
     "shell.execute_reply": "2024-07-02T15:23:07.828645Z",
     "shell.execute_reply.started": "2024-07-02T15:23:07.819300Z"
    }
   },
   "outputs": [],
   "source": [
    "Q = Q.view(1, -1, n_heads, embed_dim//n_heads).transpose(1, 2)\n",
    "K = K.view(1, -1, n_heads, embed_dim//n_heads).transpose(1, 2)\n",
    "V = V.view(1, -1, n_heads, embed_dim//n_heads).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb70491-f50c-4865-83bb-3ed7ee440d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f040a007",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:21:43.720734Z",
     "start_time": "2023-11-02T15:21:43.510493Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1622d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:23:19.115642Z",
     "start_time": "2023-11-02T15:23:19.112013Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9710650d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:02:29.665514Z",
     "start_time": "2023-11-02T16:02:26.697762Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = AutoModelForCausalLM.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298af5c1",
   "metadata": {},
   "source": [
    "## model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2004a71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:26:17.843004Z",
     "start_time": "2023-11-02T15:26:17.833347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65170e8",
   "metadata": {},
   "source": [
    "## word embedding & lm_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7156b5c1",
   "metadata": {},
   "source": [
    "- The GPT2 Model transformer with a **language modeling head on top** (lm_head) (linear layer with weights **tied** to the input embeddings).\n",
    "    - https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d448a480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:23:51.227844Z",
     "start_time": "2023-11-02T15:23:51.198899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.transformer.wte.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1584e46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T15:23:58.641914Z",
     "start_time": "2023-11-02T15:23:58.631742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e3410c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:02:37.220295Z",
     "start_time": "2023-11-02T16:02:37.211932Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gpt2.lm_head.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c27bc6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:02:40.640181Z",
     "start_time": "2023-11-02T16:02:40.631575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.lm_head.weight is gpt2.transformer.wte.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49fc4405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:02:43.614274Z",
     "start_time": "2023-11-02T16:02:43.596853Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
      "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
      "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
      "        ...,\n",
      "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
      "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
      "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]])\n",
      "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
      "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
      "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
      "        ...,\n",
      "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
      "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
      "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]])\n"
     ]
    }
   ],
   "source": [
    "print(gpt2.state_dict()['transformer.wte.weight'])\n",
    "print(gpt2.state_dict()['lm_head.weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb60a24",
   "metadata": {},
   "source": [
    "### tied or shared tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91432ee",
   "metadata": {},
   "source": [
    "- https://huggingface.co/docs/safetensors/torch_shared_tensors\n",
    "\n",
    "    - Pytorch uses shared tensors for some computation. This is extremely interesting to reduce memory usage in general.\n",
    "\n",
    "    - One very classic use case is in transformers the embeddings are shared with lm_head. By using the same matrix, the model uses less parameters, and gradients flow much better to the embeddings (which is the start of the model, so they donâ€™t flow easily there, whereas lm_head is at the tail of the model, so gradients are extremely good over there, since they are the same tensors, they both benefit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bbabe74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:03:19.585029Z",
     "start_time": "2023-11-02T16:03:19.569927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['a.weight', 'a.bias', 'b.weight', 'b.bias'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(100, 100)\n",
    "        self.b = nn.Linear(100, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.b(self.a(x))\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(model.state_dict())\n",
    "# odict_keys(['a.weight', 'a.bias', 'b.weight', 'b.bias'])\n",
    "torch.save(model.state_dict(), \"model.bin\")\n",
    "# This file is now 41k instead of ~80k, because A and B are the same weight hence only 1 is saved on disk with both `a` and `b` pointing to the same buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6cf1c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T16:02:49.658855Z",
     "start_time": "2023-11-02T16:02:49.635945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a.weight', tensor([[ 0.0777,  0.0683,  0.0710,  ...,  0.0692,  0.0377,  0.0951],\n",
      "        [ 0.0986,  0.0207, -0.0691,  ...,  0.0168,  0.0718, -0.0220],\n",
      "        [ 0.0806, -0.0145, -0.0851,  ...,  0.0653,  0.0729, -0.0443],\n",
      "        ...,\n",
      "        [ 0.0818, -0.0725,  0.0595,  ..., -0.0729,  0.0758,  0.0752],\n",
      "        [ 0.0983, -0.0282, -0.0066,  ..., -0.0467, -0.0237, -0.0505],\n",
      "        [-0.0291, -0.0101, -0.0842,  ..., -0.0088, -0.0748,  0.0641]])), ('a.bias', tensor([ 0.0377,  0.0652,  0.0465, -0.0092,  0.0909,  0.0700, -0.0753, -0.0464,\n",
      "        -0.0905, -0.0142,  0.0044,  0.0673, -0.0510,  0.0401,  0.0207, -0.0703,\n",
      "         0.0661, -0.0329, -0.0917,  0.0600,  0.0594,  0.0968,  0.0822, -0.0912,\n",
      "         0.0221,  0.0809, -0.0047, -0.0823,  0.0861,  0.0808, -0.0131, -0.0903,\n",
      "        -0.0515,  0.0507, -0.0054,  0.0317, -0.0846, -0.0964,  0.0124, -0.0123,\n",
      "         0.0576,  0.0543, -0.0357,  0.0272,  0.0058, -0.0178,  0.0899,  0.0117,\n",
      "         0.0805, -0.0146, -0.0219,  0.0898,  0.0014,  0.0348,  0.0245, -0.0595,\n",
      "         0.0766,  0.0728,  0.0643, -0.0987, -0.0003, -0.0414,  0.0767, -0.0187,\n",
      "        -0.0224,  0.0797,  0.0614, -0.0766,  0.0446, -0.0091,  0.0286,  0.0228,\n",
      "         0.0843,  0.0702, -0.0594,  0.0831, -0.0560,  0.0565, -0.0780,  0.0018,\n",
      "         0.0831,  0.0598, -0.0688, -0.0731, -0.0150,  0.0103, -0.0475, -0.0635,\n",
      "        -0.0943,  0.0312, -0.0791,  0.0889,  0.0783,  0.0273,  0.0075,  0.0648,\n",
      "        -0.0479, -0.0622,  0.0339, -0.0003])), ('b.weight', tensor([[ 0.0777,  0.0683,  0.0710,  ...,  0.0692,  0.0377,  0.0951],\n",
      "        [ 0.0986,  0.0207, -0.0691,  ...,  0.0168,  0.0718, -0.0220],\n",
      "        [ 0.0806, -0.0145, -0.0851,  ...,  0.0653,  0.0729, -0.0443],\n",
      "        ...,\n",
      "        [ 0.0818, -0.0725,  0.0595,  ..., -0.0729,  0.0758,  0.0752],\n",
      "        [ 0.0983, -0.0282, -0.0066,  ..., -0.0467, -0.0237, -0.0505],\n",
      "        [-0.0291, -0.0101, -0.0842,  ..., -0.0088, -0.0748,  0.0641]])), ('b.bias', tensor([ 0.0377,  0.0652,  0.0465, -0.0092,  0.0909,  0.0700, -0.0753, -0.0464,\n",
      "        -0.0905, -0.0142,  0.0044,  0.0673, -0.0510,  0.0401,  0.0207, -0.0703,\n",
      "         0.0661, -0.0329, -0.0917,  0.0600,  0.0594,  0.0968,  0.0822, -0.0912,\n",
      "         0.0221,  0.0809, -0.0047, -0.0823,  0.0861,  0.0808, -0.0131, -0.0903,\n",
      "        -0.0515,  0.0507, -0.0054,  0.0317, -0.0846, -0.0964,  0.0124, -0.0123,\n",
      "         0.0576,  0.0543, -0.0357,  0.0272,  0.0058, -0.0178,  0.0899,  0.0117,\n",
      "         0.0805, -0.0146, -0.0219,  0.0898,  0.0014,  0.0348,  0.0245, -0.0595,\n",
      "         0.0766,  0.0728,  0.0643, -0.0987, -0.0003, -0.0414,  0.0767, -0.0187,\n",
      "        -0.0224,  0.0797,  0.0614, -0.0766,  0.0446, -0.0091,  0.0286,  0.0228,\n",
      "         0.0843,  0.0702, -0.0594,  0.0831, -0.0560,  0.0565, -0.0780,  0.0018,\n",
      "         0.0831,  0.0598, -0.0688, -0.0731, -0.0150,  0.0103, -0.0475, -0.0635,\n",
      "        -0.0943,  0.0312, -0.0791,  0.0889,  0.0783,  0.0273,  0.0075,  0.0648,\n",
      "        -0.0479, -0.0622,  0.0339, -0.0003]))])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(100, 100)\n",
    "        self.b = self.a\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.b(self.a(x))\n",
    "\n",
    "\n",
    "model = Model()\n",
    "print(model.state_dict())\n",
    "# odict_keys(['a.weight', 'a.bias', 'b.weight', 'b.bias'])\n",
    "torch.save(model.state_dict(), \"model2.bin\")\n",
    "# This file is now 41k instead of ~80k, because A and B are the same weight hence only 1 is saved on disk with both `a` and `b` pointing to the same buffer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

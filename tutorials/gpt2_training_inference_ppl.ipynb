{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a753963-40a8-4e2d-a10f-bfb31fc07af8",
   "metadata": {},
   "source": [
    "> 1. 现代式语言模型，或者现代式人工智能最最核心的是 Transformer 架构，Transformer 架构最特色底层的计算机制是 Attention；\n",
    "> 2. 在 Transformer 架构上，在 Attention 计算上花再多的时间探索都是值得的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdb035b3-f536-427a-b551-82459cf757f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:40:03.875462Z",
     "iopub.status.busy": "2024-06-22T03:40:03.875095Z",
     "iopub.status.idle": "2024-06-22T03:40:03.888278Z",
     "shell.execute_reply": "2024-06-22T03:40:03.886039Z",
     "shell.execute_reply.started": "2024-06-22T03:40:03.875435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x72694a27ac50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98b211-ecca-4628-bb32-49186fb06974",
   "metadata": {},
   "source": [
    "## review GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01ee35-a47a-4a45-a1c5-6456fd2520c6",
   "metadata": {},
   "source": [
    "\n",
    "- 重新 review GPT 的过程\n",
    "    - input_ids: 1*1024, 一个（bs）长度为 1024 的 token ids\n",
    "    - last_hidden_states: 1\\*1024\\*768\n",
    "        - last layer hidden states of (transformer)\n",
    "    - lm_logits: 1\\*1024\\*50257\n",
    "        - lm head，将每一个位置上的 token 的 hidden state，映射到整个词表维度上的概率分布输出\n",
    "        \n",
    "- shift labels 与损失计算\n",
    "\n",
    "    ```\n",
    "    labels = labels.to(lm_logits.device)\n",
    "    \n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "    \n",
    "    # Flatten the tokens\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f242c9-ba84-42c2-ad41-e904f4c5a228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T15:20:58.914000Z",
     "iopub.status.busy": "2024-06-20T15:20:58.913405Z",
     "iopub.status.idle": "2024-06-20T15:20:58.924353Z",
     "shell.execute_reply": "2024-06-20T15:20:58.922097Z",
     "shell.execute_reply.started": "2024-06-20T15:20:58.913956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5] [1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5] [2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "logits = [1, 2, 3, 4, 5]\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "print(logits, logits[:-1])\n",
    "print(labels, labels[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc43c8-60f1-4644-977e-bddcb37d9a2c",
   "metadata": {},
   "source": [
    "### casual/decoder only 单向注意力的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d428c821-a705-40f1-af86-2c615bff24c5",
   "metadata": {},
   "source": [
    "- BERT：双向注意力（bidirectional self attention）\n",
    "\n",
    "    $$\n",
    "    \\quad \\text{Attention}(Q^{(n \\times d_k)}, K^{(n \\times d_k)}, V^{(n \\times d_v)}) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \n",
    "    $$\n",
    "\n",
    "- GPT：单向因果注意力（causal self attention）\n",
    "\n",
    "    $$\n",
    "    \\quad \\text{Attention}(Q^{(n \\times d_k)}, K^{(n \\times d_k)}, V^{(n \\times d_v)}) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}+ M\\right)V\n",
    "    $$\n",
    "\n",
    "    - $M_{ij}=0, j\\ge i$\n",
    "    - $M_{ij}=1, j\\leq i$\n",
    "    \n",
    "    $$\n",
    "    M = \\begin{pmatrix}\n",
    "    1 & -\\infty & -\\infty & \\cdots & -\\infty \\\\\n",
    "    1 & 1 & -\\infty & \\cdots & -\\infty \\\\\n",
    "    1 & 1 & 1 & \\cdots & -\\infty \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    1 & 1 & 1 & \\cdots & 1\n",
    "    \\end{pmatrix}_{n\\times n}\n",
    "    $$\n",
    "\n",
    "- T5：encoder 输出 K/V（取值相同），decoder 输出 Q，两者做 Cross attention\n",
    "\n",
    "    $$\n",
    "    \\begin{split}\n",
    "    \\text{Encoder Self-Attention} &: \\quad \\text{Attention}(Q^{(n \\times d_k)}, K^{(n \\times d_k)}, V^{(n \\times d_v)}) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\\\\\n",
    "    \\text{Decoder Masked Self-Attention} & : \\quad \\text{Attention}(Q^{(m \\times d_k)}, K^{(m \\times d_k)}, V^{(m \\times d_v)}) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}+M\\right)V \\\\\n",
    "    \\text{Cross-Attention} & : \\quad \\text{Attention}(Q^{(m \\times d_k)}, K^{(n \\times d_k)}, V^{(n \\times d_v)}) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\\\\n",
    "    \\end{split}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e5c8b7-817b-4295-b2fa-f443885dbf31",
   "metadata": {},
   "source": [
    "\n",
    "- modeling_gpt2.py\n",
    "    - GPT2Attention._attn\n",
    "\n",
    "```\n",
    "if not self.is_cross_attention:\n",
    "    # if only \"normal\" attention layer implements causal mask\n",
    "    query_length, key_length = query.size(-2), key.size(-2)\n",
    "    causal_mask = self.bias[:, :, key_length - query_length : key_length, :key_length]\n",
    "    mask_value = torch.finfo(attn_weights.dtype).min\n",
    "    # Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\n",
    "    # Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\n",
    "    mask_value = torch.full([], mask_value, dtype=attn_weights.dtype, device=attn_weights.device)\n",
    "    attn_weights = torch.where(causal_mask, attn_weights.to(attn_weights.dtype), mask_value)\n",
    "\n",
    "if attention_mask is not None:\n",
    "    # Apply the attention mask\n",
    "    attn_weights = attn_weights + attention_mask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b86be-3536-4691-8887-93bb1d104815",
   "metadata": {},
   "source": [
    "### CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46579a6a-7b62-4aca-a6ec-cff0d74e0eb4",
   "metadata": {},
   "source": [
    "计算的角度\n",
    "- labels 起到选择的作用\n",
    "- ignore_index：过滤（-100）\n",
    "    - PPL 计算的时候会用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bc31e0e-80a2-45ae-a24b-2e7ecc71276b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:38:06.646967Z",
     "iopub.status.busy": "2024-06-22T03:38:06.646325Z",
     "iopub.status.idle": "2024-06-22T03:38:06.655706Z",
     "shell.execute_reply": "2024-06-22T03:38:06.653748Z",
     "shell.execute_reply.started": "2024-06-22T03:38:06.646923Z"
    }
   },
   "outputs": [],
   "source": [
    "# -100，labels（token id） 提供一个选择器\n",
    "\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fc2f6de-c5d0-49ad-88ac-a2efa0b983e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:38:08.645684Z",
     "iopub.status.busy": "2024-06-22T03:38:08.645101Z",
     "iopub.status.idle": "2024-06-22T03:38:08.658563Z",
     "shell.execute_reply": "2024-06-22T03:38:08.656430Z",
     "shell.execute_reply.started": "2024-06-22T03:38:08.645642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229],\n",
       "        [-0.1863,  2.2082, -0.6380,  0.4617,  0.2674],\n",
       "        [ 0.5349,  0.8094,  1.1103, -1.6898, -0.9890]], requires_grad=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token-wise logits (transformer output)\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "759127d3-2cfa-40da-bcf0-bf0c62fa402b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:38:12.328127Z",
     "iopub.status.busy": "2024-06-22T03:38:12.327510Z",
     "iopub.status.idle": "2024-06-22T03:38:12.341619Z",
     "shell.execute_reply": "2024-06-22T03:38:12.339545Z",
     "shell.execute_reply.started": "2024-06-22T03:38:12.328084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "751463b7-1439-4297-8f3b-6f1459fb1f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:39:19.346153Z",
     "iopub.status.busy": "2024-06-22T03:39:19.345515Z",
     "iopub.status.idle": "2024-06-22T03:39:19.360030Z",
     "shell.execute_reply": "2024-06-22T03:39:19.357906Z",
     "shell.execute_reply.started": "2024-06-22T03:39:19.346108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4607, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.3367, 0.2674, -1.6898\n",
    "output = loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64e1529b-d1e3-423b-87c1-d53b0ca391c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:40:51.845109Z",
     "iopub.status.busy": "2024-06-22T03:40:51.844623Z",
     "iopub.status.idle": "2024-06-22T03:40:51.858525Z",
     "shell.execute_reply": "2024-06-22T03:40:51.856478Z",
     "shell.execute_reply.started": "2024-06-22T03:40:51.845071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3472, -1.5551, -1.4494, -1.4535, -2.8067],\n",
       "        [-2.7779, -0.3834, -3.2296, -2.1299, -2.3242],\n",
       "        [-1.4860, -1.2116, -0.9107, -3.7108, -3.0099]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1.3472, -2.3242, -3.7108\n",
    "F.log_softmax(input, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ca97da1-3af1-4191-b1fe-2255688b685a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:41:33.986068Z",
     "iopub.status.busy": "2024-06-22T03:41:33.985431Z",
     "iopub.status.idle": "2024-06-22T03:41:33.998322Z",
     "shell.execute_reply": "2024-06-22T03:41:33.996114Z",
     "shell.execute_reply.started": "2024-06-22T03:41:33.986023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.460733333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1.3472 + (-2.3242) + (-3.7108))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "699ab59a-95bc-43e5-8410-36f3e2f8808d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:42:08.096948Z",
     "iopub.status.busy": "2024-06-22T03:42:08.096349Z",
     "iopub.status.idle": "2024-06-22T03:42:08.109951Z",
     "shell.execute_reply": "2024-06-22T03:42:08.108102Z",
     "shell.execute_reply.started": "2024-06-22T03:42:08.096905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    4, -100])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[-1] = -100\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d09deded-feac-4333-9406-9de8ea4cb7ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:42:21.447582Z",
     "iopub.status.busy": "2024-06-22T03:42:21.446937Z",
     "iopub.status.idle": "2024-06-22T03:42:21.461060Z",
     "shell.execute_reply": "2024-06-22T03:42:21.458894Z",
     "shell.execute_reply.started": "2024-06-22T03:42:21.447537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8357, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e6bd647-fd72-4a79-b48d-a7322670c279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:43:00.266958Z",
     "iopub.status.busy": "2024-06-22T03:43:00.266270Z",
     "iopub.status.idle": "2024-06-22T03:43:00.279511Z",
     "shell.execute_reply": "2024-06-22T03:43:00.277565Z",
     "shell.execute_reply.started": "2024-06-22T03:43:00.266909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8356999999999999"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-1.3472 + (-2.3242))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e1c31-0c59-46ff-86a6-dfc4610d18ea",
   "metadata": {},
   "source": [
    "## Training & Inference/Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e600256-37fc-4913-b4b2-61360be1cc05",
   "metadata": {},
   "source": [
    "- llama2/3 inference code: autoregressive, token by token generation\n",
    "    - https://github.com/meta-llama/llama3/blob/main/llama/generation.py#L179-L192C13\n",
    "- training 的时候，因为有 casual mask（下三角矩阵的存在），等价于 autoregressive，token by token\n",
    "- 计算 PPL （语言模型训练好坏的一个指标）的过程就是已有文本的测试集，可以用 casual mask的方式实现自注意力，实现 autoregressive，token by token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41852fd1-55ab-4322-ab97-3e4b533a4ab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:23:29.217769Z",
     "iopub.status.busy": "2024-06-22T03:23:29.217189Z",
     "iopub.status.idle": "2024-06-22T03:23:32.777290Z",
     "shell.execute_reply": "2024-06-22T03:23:32.775870Z",
     "shell.execute_reply.started": "2024-06-22T03:23:29.217728Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# 初始化模型和tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2').to('cuda')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# 输入序列\n",
    "input_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d47dc47-9223-43da-b535-312c50e22c6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:26:47.004043Z",
     "iopub.status.busy": "2024-06-22T03:26:47.001738Z",
     "iopub.status.idle": "2024-06-22T03:26:47.014826Z",
     "shell.execute_reply": "2024-06-22T03:26:47.012607Z",
     "shell.execute_reply.started": "2024-06-22T03:26:47.003981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "149682a3-92d3-4d0b-b71a-10d17419a22f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:31:38.492047Z",
     "iopub.status.busy": "2024-06-22T03:31:38.491412Z",
     "iopub.status.idle": "2024-06-22T03:31:38.546463Z",
     "shell.execute_reply": "2024-06-22T03:31:38.544226Z",
     "shell.execute_reply.started": "2024-06-22T03:31:38.492002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 9, 50257]),\n",
       " tensor([[[-62.3139, -61.5645, -66.4938,  ..., -68.1286, -68.3228, -63.5829],\n",
       "          [-66.3240, -66.7452, -72.1618,  ..., -75.1955, -73.4650, -68.1786],\n",
       "          [-88.2910, -88.7236, -93.4422,  ..., -98.6211, -90.6379, -90.9913],\n",
       "          ...,\n",
       "          [-80.7563, -82.8596, -87.4034,  ..., -91.0716, -89.5648, -84.5701],\n",
       "          [-94.8247, -94.5054, -97.7886,  ..., -97.1508, -98.4995, -96.5095],\n",
       "          [-88.8787, -87.6110, -92.3262,  ..., -95.8310, -93.5163, -91.9581]]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(input_ids.to('cuda'), )\n",
    "logits = outputs.logits\n",
    "logits.shape, logits[:, 1:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ba13a7-0023-4230-a1d1-262bb691f930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:30:37.444242Z",
     "iopub.status.busy": "2024-06-22T03:30:37.443593Z",
     "iopub.status.idle": "2024-06-22T03:30:37.595544Z",
     "shell.execute_reply": "2024-06-22T03:30:37.593699Z",
     "shell.execute_reply.started": "2024-06-22T03:30:37.444195Z"
    }
   },
   "outputs": [],
   "source": [
    "# 逐步生成每个 token，并输出每一步的 logits\n",
    "generated_logits = []\n",
    "\n",
    "# 从第一个 token 开始逐步生成\n",
    "for i in range(1, input_ids.size(1)):\n",
    "    step_input_ids = input_ids[:, :i]  # 当前步骤的输入序列\n",
    "    outputs = model(step_input_ids.to('cuda'))\n",
    "    logits = outputs.logits\n",
    "    next_token_logits = logits[:, -1, :]  # 获取最后一个token的logits\n",
    "    generated_logits.append(next_token_logits)\n",
    "\n",
    "generated_logits = torch.stack(generated_logits, dim=1)[:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1716ce98-da13-4ae2-b8f2-0c6cebdb902b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:31:53.741448Z",
     "iopub.status.busy": "2024-06-22T03:31:53.740820Z",
     "iopub.status.idle": "2024-06-22T03:31:53.760032Z",
     "shell.execute_reply": "2024-06-22T03:31:53.757937Z",
     "shell.execute_reply.started": "2024-06-22T03:31:53.741402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 50257]),\n",
       " tensor([[[-62.3139, -61.5645, -66.4938,  ..., -68.1286, -68.3228, -63.5829],\n",
       "          [-66.3240, -66.7452, -72.1618,  ..., -75.1955, -73.4651, -68.1786],\n",
       "          [-88.2909, -88.7236, -93.4422,  ..., -98.6211, -90.6378, -90.9913],\n",
       "          ...,\n",
       "          [-80.7563, -82.8596, -87.4034,  ..., -91.0716, -89.5648, -84.5701],\n",
       "          [-94.8247, -94.5054, -97.7886,  ..., -97.1508, -98.4995, -96.5095],\n",
       "          [-88.8787, -87.6110, -92.3262,  ..., -95.8310, -93.5163, -91.9581]]],\n",
       "        device='cuda:0', grad_fn=<SliceBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_logits.shape, generated_logits[:, 1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9a5ee-1f60-4c48-adaf-ef991fe8372b",
   "metadata": {},
   "source": [
    "## PPL 指标的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d49e41ad-fddf-4bf7-98f6-8f723ac0ba4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:44:44.352989Z",
     "iopub.status.busy": "2024-06-22T03:44:44.352348Z",
     "iopub.status.idle": "2024-06-22T03:44:44.855481Z",
     "shell.execute_reply": "2024-06-22T03:44:44.854611Z",
     "shell.execute_reply.started": "2024-06-22T03:44:44.352944Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24145713-676a-4938-9bab-67350f5ad65e",
   "metadata": {},
   "source": [
    "stride < seq_len: 刻画着一种 overlap，通过对 overlap 内的 label 置为 -100，避免重复计算；\n",
    "\n",
    "- [0, 1024): \n",
    "- [512, 1024+512)：区间长度是 1024，计算 CrossEntropy loss 的 trg_len \n",
    "    - trg_len (计算 CrossEntropy loss): 512\n",
    "- [1024, 1024+1024)\n",
    "    - trg_len (计算 CrossEntropy loss): 512\n",
    "- [1024+512, 1024+1024+512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acda284f-1ca2-4704-89d1-0235b7fdabfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T03:52:32.472420Z",
     "iopub.status.busy": "2024-06-22T03:52:32.470997Z",
     "iopub.status.idle": "2024-06-22T03:53:33.997580Z",
     "shell.execute_reply": "2024-06-22T03:53:33.996731Z",
     "shell.execute_reply.started": "2024-06-22T03:52:32.472388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████▉| 560/562 [00:07<00:00, 73.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.1880, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "\n",
    "model_id = \"openai-community/gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to('cuda')\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "encodings = tokenizer(\"\\n\\n\".join(test_dataset[\"text\"]), return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "max_length = model.config.n_positions\n",
    "stride = 512\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "\n",
    "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "    end_loc = min(begin_loc + max_length, seq_len)\n",
    "    trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to('cuda')\n",
    "    # print('input_ids', input_ids)\n",
    "\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    # print(begin_loc, end_loc, trg_len, prev_end_loc)\n",
    "\n",
    "    # assert torch.allclose(input_ids, target_ids), (input_ids.shape, target_ids.shape)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "        # to the left by 1.\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "    prev_end_loc = end_loc\n",
    "    if end_loc == seq_len:\n",
    "        break\n",
    "\n",
    "print(torch.exp(torch.stack(nlls).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

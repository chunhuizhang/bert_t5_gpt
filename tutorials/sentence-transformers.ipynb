{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c8e99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:10:55.297334Z",
     "start_time": "2024-02-04T13:10:55.289842Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d9bca",
   "metadata": {},
   "source": [
    "- Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\n",
    "    - https://arxiv.org/abs/1908.10084\n",
    "- reference\n",
    "    - https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5bcce71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:51:05.028609Z",
     "start_time": "2024-02-04T13:51:05.021766Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers\n",
    "# sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a3430573",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:47:50.511600Z",
     "start_time": "2024-02-04T13:47:50.505479Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df55abbd",
   "metadata": {},
   "source": [
    "## sentence level tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b8385",
   "metadata": {},
   "source": [
    "- NLI (natural language inferencing): 句子间关系\n",
    "    - This task receives two input sentences and outputs either “entailment”, “contradiction” or “neutral”.\n",
    "    - entailment: sentence1 entails sentence 2\n",
    "    - contradiction: sentence1 contradicts sentence2\n",
    "    - neutral: the two sentences have no relation.\n",
    "- STS (sentence textual similarity):\n",
    "    - This task receives two sentences and decides the similarity of them. Often similarity is calculated using cosine similarity function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691872f",
   "metadata": {},
   "source": [
    "## demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af3af3",
   "metadata": {},
   "source": [
    "- `paraphrase-MiniLM-L6-v2`\n",
    "    - embedding dimension：384 = 32*12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91f1d9",
   "metadata": {},
   "source": [
    "```\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "embed_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "embed_1 = embed_model.encode(sentence1, convert_to_tensor=True)\n",
    "embed_2 = embed_model.encode(sentence2, convert_to_tensor=True)\n",
    "cos_sim = util.pytorch_cos_sim(embed_1, embed_2).item()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d0643d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T12:51:13.461444Z",
     "start_time": "2024-02-04T12:51:07.432508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 20:51:09,363] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whaow/anaconda3/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1806926727294922\n",
      "-0.12082745879888535\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "embed_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "embed_1 = embed_model.encode('the movie is great!', convert_to_tensor=True)\n",
    "embed_2 = embed_model.encode('positive', convert_to_tensor=True)\n",
    "cos_sim = util.pytorch_cos_sim(embed_1, embed_2).item()\n",
    "print(cos_sim)\n",
    "embed_3 = embed_model.encode('negative', convert_to_tensor=True)\n",
    "cos_sim = util.pytorch_cos_sim(embed_1, embed_3).item()\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aea33c",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f616e8",
   "metadata": {},
   "source": [
    "### bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f215a6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:11:10.283087Z",
     "start_time": "2024-02-04T13:11:10.271883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhd9gsQGBcPWduThINIIUQ.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhd9gsQGBcPWduThINIIUQ.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225d204",
   "metadata": {},
   "source": [
    "- BERT is very good at learning the meaning of words/tokens. \n",
    "    - But It is not good at learning meaning of sentences.\n",
    "    -  sentence classification, sentence pair-wise similarity.\n",
    "- BERT produces token embedding, one way to get sentence embedding out of BERT is to average the embedding of all tokens. \n",
    "    - SentenceTransformer paper showed this produces very low quality sentence embeddings almost as bad as getting GLOVE embeddings. These embeddings do not capture the meaning of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936a1084",
   "metadata": {},
   "source": [
    "### Training BERT on NLI (classification objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df15192",
   "metadata": {},
   "source": [
    "Siamese network. Siamese means twins and it consists of two networks of the exact same architecture that they share weight too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47e2563b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:17:30.325763Z",
     "start_time": "2024-02-04T13:17:30.315233Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XB85tOf1kWmpZxoTC3ab5g.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XB85tOf1kWmpZxoTC3ab5g.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3a1448",
   "metadata": {},
   "source": [
    "- sentence u => `emb(u)` (768d)\n",
    "- sentence v => `emb(v)` (768d)\n",
    "- `emb(u)-emb(v)` (768d)\n",
    "\n",
    "$$\n",
    "o=\\text{softmax}(W_t(u,v,u-v))\n",
    "$$\n",
    "\n",
    "- cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c5bbab",
   "metadata": {},
   "source": [
    "### Training BERT on STS (regression objective)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "76590d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:48:02.271798Z",
     "start_time": "2024-02-04T13:48:02.233374Z"
    }
   },
   "outputs": [],
   "source": [
    "losses.ContrastiveLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87ce87cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:21:22.115674Z",
     "start_time": "2024-02-04T13:21:22.106289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQ4H_KErGUroYQ-59WhARA.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQ4H_KErGUroYQ-59WhARA.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e415b7a",
   "metadata": {},
   "source": [
    "- Sentence textual similarity task receives two sentences and computes their similarity. \n",
    "- The network architecture for fine-tuning BERT on STS is as following. It is again a siamese network with mean pooling on top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f645e5",
   "metadata": {},
   "source": [
    "### Training BERT on Triplet dataset (triplet objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e023e7f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:25:21.274040Z",
     "start_time": "2024-02-04T13:25:21.265609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KPhp8A6pFsue7F8z8sF6-A.png\" width=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KPhp8A6pFsue7F8z8sF6-A.png', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4a8c7",
   "metadata": {},
   "source": [
    "\n",
    "To collect this data in text domain, we can pick a random sentence from a document as anchor, pick its following sentence as positive and pick a random sentence from a different passage as negative.\n",
    "\n",
    "\n",
    "- In triplet objective, the model receives an anchor data point, \n",
    "- a positive data point that is related or close to the anchor, \n",
    "- and a negative data point that is unrelated to the anchor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8b000",
   "metadata": {},
   "source": [
    "$$\n",
    "|a-p|\\lt |a-n|\\\\\n",
    "L: = \\max (0, |a-p|-|a-m|+\\epsilon)\\\\\n",
    "|a-p| \\leq |a-m|-\\epsilon\\\\\n",
    "\\Downarrow \\\\\n",
    "L=0\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7786b",
   "metadata": {},
   "source": [
    "## pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7705ff0",
   "metadata": {},
   "source": [
    "### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe10f369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:27:20.409716Z",
     "start_time": "2024-02-04T13:27:20.402671Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac8c942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:30:24.700775Z",
     "start_time": "2024-02-04T13:29:44.216563Z"
    }
   },
   "outputs": [],
   "source": [
    "word_embed_model = models.Transformer('bert-base-uncased')\n",
    "# a pool function over the token embeddings\n",
    "pooling_model = models.Pooling(word_embed_model.get_word_embedding_dimension(), \n",
    "                               pooling_mode = 'cls',\n",
    "                               pooling_mode_cls_token=True, \n",
    "                               pooling_mode_mean_tokens = False)\n",
    "model = SentenceTransformer(modules=[word_embed_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5341ac0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:30:38.112584Z",
     "start_time": "2024-02-04T13:30:38.103313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed_model.get_word_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "857d71e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:18:42.469980Z",
     "start_time": "2024-02-04T14:18:42.459486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b34ae",
   "metadata": {},
   "source": [
    "### 数据与任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfad5190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:12:50.849751Z",
     "start_time": "2024-02-04T14:12:50.844441Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b95223e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:13:38.445201Z",
     "start_time": "2024-02-04T14:12:51.834250Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21e87e88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:34:52.570093Z",
     "start_time": "2024-02-04T13:34:52.559907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58ada8cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:34:57.697427Z",
     "start_time": "2024-02-04T13:34:57.684449Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aca8b385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:41:03.910129Z",
     "start_time": "2024-02-04T13:41:03.903642Z"
    }
   },
   "outputs": [],
   "source": [
    "# texts/label/guid\n",
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ce380763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:25:57.359030Z",
     "start_time": "2024-02-04T14:25:57.126807Z"
    }
   },
   "outputs": [],
   "source": [
    "training_ds = []\n",
    "for example in dataset['train']:\n",
    "    training_ds.append(InputExample(texts=[example['sentence1'], example['sentence2']], \n",
    "                                    label=float(example['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "282af8f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:25:59.041551Z",
     "start_time": "2024-02-04T14:25:59.034827Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3215f2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:00.556906Z",
     "start_time": "2024-02-04T14:26:00.549737Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_ds, shuffle=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9ea9eacc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:02.150977Z",
     "start_time": "2024-02-04T14:26:02.140389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(len(training_ds)/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "13580348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:03.785540Z",
     "start_time": "2024-02-04T14:26:03.775685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "40710b1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:29.088154Z",
     "start_time": "2024-02-04T14:26:29.083320Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch = next(iter(train_loader))\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "13dfb35d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:43.461191Z",
     "start_time": "2024-02-04T14:26:43.455884Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch[0][0]['input_ids'].shape\n",
    "# batch[0][1]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d24b15",
   "metadata": {},
   "source": [
    "### training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8dd063ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:26:46.859422Z",
     "start_time": "2024-02-04T14:26:46.850958Z"
    }
   },
   "outputs": [],
   "source": [
    "train_examples = [\n",
    "    InputExample(texts=['This is a positive pair', 'Where the distance will be minimized'], label=1),\n",
    "    InputExample(texts=['This is a negative pair', 'Their distance will be increased'], label=0)]\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "716d5e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:23:49.668151Z",
     "start_time": "2024-02-04T14:23:49.553505Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'sentence_transformers.readers.InputExample.InputExample'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'sentence_transformers.readers.InputExample.InputExample'>"
     ]
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57a37841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:46:45.279493Z",
     "start_time": "2024-02-04T13:46:45.253187Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c365903e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:46:57.887056Z",
     "start_time": "2024-02-04T13:46:57.840309Z"
    }
   },
   "outputs": [],
   "source": [
    "losses.ContrastiveLoss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b212052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:46:49.554128Z",
     "start_time": "2024-02-04T13:46:49.546988Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = losses.ContrastiveLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6baac150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:17:32.123903Z",
     "start_time": "2024-02-04T14:17:32.114089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8ea72391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:19:29.968210Z",
     "start_time": "2024-02-04T14:19:29.906861Z"
    }
   },
   "outputs": [],
   "source": [
    "model.encode??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521a3a2",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f027c1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:09:44.409775Z",
     "start_time": "2024-02-04T14:09:44.403496Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "391232b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:09:37.646838Z",
     "start_time": "2024-02-04T14:09:37.592190Z"
    }
   },
   "outputs": [],
   "source": [
    "s1s = []\n",
    "s2s = []\n",
    "scores = []\n",
    "for example in dataset['validation']:\n",
    "    s1s.append(example['sentence1'])\n",
    "    s2s.append(example['sentence2'])\n",
    "    scores.append(float(example['label']))\n",
    "evaluator = evaluation.BinaryClassificationEvaluator(s1s, s2s, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d50142a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:59:23.824519Z",
     "start_time": "2024-02-04T13:56:08.335505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88285910ff3f4f75b39da4be7a41b89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2012c0ea95f4c98a722b9a5c72cc01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./sentence_transformer//config.json\n",
      "Model weights saved in ./sentence_transformer//pytorch_model.bin\n",
      "tokenizer config file saved in ./sentence_transformer//tokenizer_config.json\n",
      "Special tokens file saved in ./sentence_transformer//special_tokens_map.json\n",
      "Configuration saved in ./sentence_transformer//config.json\n",
      "Model weights saved in ./sentence_transformer//pytorch_model.bin\n",
      "tokenizer config file saved in ./sentence_transformer//tokenizer_config.json\n",
      "Special tokens file saved in ./sentence_transformer//special_tokens_map.json\n",
      "Configuration saved in ./sentence_transformer//config.json\n",
      "Model weights saved in ./sentence_transformer//pytorch_model.bin\n",
      "tokenizer config file saved in ./sentence_transformer//tokenizer_config.json\n",
      "Special tokens file saved in ./sentence_transformer//special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757a11e253f94d41b9d9517ca9a70a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294978cbe965466a8d56d3e7b760c908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83511622df4a4bffa1fe6b8fde1b6ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afd8a0318c041dcaf24be1fa3734904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/459 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "model.fit(\n",
    "    train_objectives=[(train_loader, train_loss)], \n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=200,\n",
    "    epochs=5, \n",
    "    warmup_steps=0,\n",
    "    output_path='./sentence_transformer/',\n",
    "    weight_decay=0.01,\n",
    "    optimizer_params={'lr': 0.00004},\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431f8ca",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f165533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T13:59:26.716654Z",
     "start_time": "2024-02-04T13:59:26.671676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07039643 -0.15299119  0.21200444 ... -0.0314035   0.10178623\n",
      "   0.23059756]\n",
      " [-0.08689684 -0.02244206 -0.02044529 ... -0.5961807  -0.04331313\n",
      "   0.21836686]]\n"
     ]
    }
   ],
   "source": [
    "sentences = ['This is just a random sentence on a friday evenning', 'to test model ability.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96e91e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:00:02.029248Z",
     "start_time": "2024-02-04T13:59:35.472166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.28\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "correct = 0\n",
    "for row in dataset['test']:\n",
    "    u = model.encode(row['sentence1'])\n",
    "    v = model.encode(row['sentence2'])\n",
    "    cos_score = util.cos_sim(u, v)[0].numpy()[0]\n",
    "    if cos_score > 0.5 and row['label'] == 1:\n",
    "        correct += 1\n",
    "    if cos_score <= 0.5 and row['label'] == 0:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db2e1ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T14:00:18.117018Z",
     "start_time": "2024-02-04T14:00:18.108275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7118840579710145\n"
     ]
    }
   ],
   "source": [
    "print(correct/len(dataset['test']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

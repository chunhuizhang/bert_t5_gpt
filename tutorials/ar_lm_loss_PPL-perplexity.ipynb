{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8869cc-2bde-40a5-b9d2-809cd713910a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ecbefb-e527-47ca-bbd9-0e7213e8e719",
   "metadata": {},
   "source": [
    "- references\n",
    "    - https://huggingface.co/docs/transformers/perplexity\n",
    "    - https://www.cnblogs.com/ZJUT-jiangnan/p/5612096.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945162a-a512-4875-82fb-1355ead5e6b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Auto-regressive model training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4f082-b0f5-4ea0-a605-b654a8a0a218",
   "metadata": {},
   "source": [
    "- 自回归模型，是词表粒度的多分类问题，用多分类问题的交叉熵定义其loss\n",
    "    - 其形式为（nll，negative log likelihood）：\n",
    "    \n",
    "    $$\n",
    "    L=-\\frac1N\\sum_{i=1}^N\\log P(y_i)\n",
    "    $$\n",
    "  \n",
    "    - LM head：one hot 分布（ground truth 分布）与预测概率分布的交叉熵；\n",
    "        - 词表粒度的分类问题\n",
    "    - 完全随机的情况下，对于 $|V|=10000$ 时，其 $\\log \\frac1{10000}=9.21$\n",
    "\n",
    "- 二分类、多分类交叉熵\n",
    "    \n",
    "    - 二分类\n",
    "    \n",
    "    $$\n",
    "    L=-\\frac1N\\sum_{i=1}^Ny_i\\log P(\\hat y_i)+(1-y_i)\\log (1-P(\\hat y_i))\n",
    "    $$\n",
    "    \n",
    "    - 多分类\n",
    "    \n",
    "    $$\n",
    "    L=-\\frac1N\\sum_{i=1}^Ny_{i,c}\\log P(\\hat y_{i,c})\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83792555-d79d-450d-a1d6-61fd3f27a8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210340371976182"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8d2d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791e26f",
   "metadata": {},
   "source": [
    "> PPL：perplexity\n",
    "\n",
    "- language model 好坏的评估指标\n",
    "    - 较低的困惑度指模型的预测更加准确。\n",
    "\n",
    "$$\n",
    "PPL=\\exp\\left(-\\frac1N\\sum_{i=1}^N\\log P(y_i)\\right)\n",
    "$$\n",
    "\n",
    "- loss of ar model\n",
    "    \n",
    "    $$\n",
    "    L=\\log PPL\n",
    "    $$\n",
    "    \n",
    "    - minimize L == minimize PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd15a7f3-1a55-4e1d-91ad-93d89f709352",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-30 10:08:24,966] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88115c0c-cd7c-48fe-a12a-e5ecff3d744d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a212bef2-9007-4a11-82c2-1e656e45b959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 4358\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73cd1aac-7cca-402e-bb11-687d87cca03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_ppl_on_ds(gpt_model_id, test_dataset, device='cuda'):\n",
    "    \n",
    "    model = GPT2LMHeadModel.from_pretrained(gpt_model_id).to(device)\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(gpt_model_id)\n",
    "    encodings = tokenizer(\"\\n\\n\".join(test_dataset[\"text\"]), return_tensors=\"pt\")\n",
    "    \n",
    "    max_length = model.config.n_positions\n",
    "    stride = 512\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "    \n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "            # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "            # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "            # to the left by 1.\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    return torch.exp(torch.stack(nlls).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6e8c23-bca3-4b86-a512-afcfe5c4a77c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to('cuda')\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)\n",
    "encodings = tokenizer(\"\\n\\n\".join(test_dataset[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9982838d-772f-4fa9-b36b-7c246036e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88c98b03-368c-4ddb-92e1-2bad599a6119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum sequence length that this model might ever be used with.\n",
    "model.config.n_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8216509c-20ca-4663-a8a3-1ae85446e09f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(range(0, 287644, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27965a59-d1e5-4495-9aeb-0e2592504eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████▉| 560/562 [00:07<00:00, 71.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(25.1880, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2\"\n",
    "model_ppl_on_ds(model_id, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ee2c81-8288-4500-bda0-7fcc5ecb9fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92d4a9be55a4628b9760ea1d28b6ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f44a2b491d24c1d9661b7fa5c746623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cb3da681cb4af899b147cb81b43565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1240f6f31d9148ba8c546a08d6d2d68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbffff147de4ebdacdda63fb367d289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69b9ac6fe864c8fbf9310ad2a15043e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475403bc9efa4c70a26008924cb628de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████▉| 560/562 [00:18<00:00, 30.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(18.4739, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2-medium\"\n",
    "model_ppl_on_ds(model_id, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa01b3a1-64e0-47f2-a867-d3784bfecb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████▉| 560/562 [00:40<00:00, 13.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(16.4541, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"openai-community/gpt2-large\"\n",
    "model_ppl_on_ds(model_id, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e854eea-3b24-40d7-a087-de7e6b0ca19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
